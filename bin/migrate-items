#!/usr/bin/env ruby
# frozen_string_literal: true

# Usage:
#   bin/migrate-items items.jsonl 0 /opt/app/local-files migration_item_type_updates.csv
#   These two just load metadata:
#   bin/migrate-items items.jsonl 1000
#   bin/migrate-items items.jsonl

require 'csv'
require_relative '../config/environment'
DEFAULT_DATA_ROOT = '/data/hydrus-files'
DATA_ROOT = ARGV[2]
CSV_FILE = ARGV[3]

warn "A data files was not provided" unless CSV_FILE
Rails.logger.level = :warn


warn "A data root was not provided, so no files will be imported" unless DATA_ROOT

STATES = {
  'published' => 'deposited',
  'draft' => 'first_draft',
  'awaiting_approval' => 'pending_approval',
  'returned' => 'rejected'
}

# ACCESS = {
#   'everyone' => 'world',
#   'stanford' => 'stanford',
#   'varies' => 'depositor-selects'
# }

LICENSE = {
  'pddl' => 'PDDL-1.0',
  'cc-by' => 'CC-BY-4.0',
  'cc-by-sa' => 'CC-BY-SA-4.0',
  'cc-by-nc' => 'CC-BY-NC-4.0',
  'cc-by-nc-sa' => 'CC-BY-NC-SA-4.0',
  'cc-by-nc-nd' => 'CC-BY-NC-ND-4.0',
  'cc-by-nd' => 'CC-BY-ND-4.0',
  'cc-pdm' => 'PDDL-1.0',
  'cc-cc0' => 'CC0-1.0',
  'odc-by' => 'ODC-By-1.0',
  'odc-odbl' => 'ODbL-1.0',
  'none' => 'none'
}

WORK_TYPE = {
  'dataset' => 'data',
  'image' => 'image',
  'video' => 'video',
  'audio - spoken' => 'sound',
  'audio - music' => 'sound',
  'other' => 'other',
  'class project' => 'other',
  'textbook' => 'text',
  'thesis' => 'text',
  'article' => 'text',
  'technical report' => 'text',
  'conference paper / presentation' => 'other',
  'software' => 'software, multimedia',
  'computer game' => 'software, multimedia',
  'archival mixed material' => 'mixed material'
}

CONTRIBUTOR_TYPE = {
  'personal' => 'person',
  'corporate' => 'organization',
  'conference' => 'organization'
}

CONTRIBUTOR_ROLE = {
  'Author' => 'Author',
  'author' => 'Author', # Bad data? about 1000 items are like this.
  'author,' => 'Author', # Bad data? 4 items have this role
  'author.' => 'Author', # Bad data? 207 items have this role
  'autor' => 'Author', # Bad data? 7 items have this role
  'Department' => 'Research group',
  'Editor' => 'Editor',
  'editor' => 'Editor',
  'editor.' => 'Editor',
  'Advisor' => 'Thesis advisor',
  'Primary advisor' => 'Primary thesis advisor',
  'Degree granting institution' => 'Degree granting institution',
  'Publisher' => 'Publisher',
  'publisher.' => 'Publisher',
  'publisher' => 'Publisher',
  'publisher,' => 'Publisher',
  'Collector' => 'Data collector',
  'Creator' => 'Creator',
  'creator' => 'Creator', # Bad data? 3 items have this role
  'Conference' => 'Conference',
  'conference' => 'Conference',
  'composer' => 'Composer',
  'composer.' => 'Composer',
  'Contributing author' => 'Contributing author',
  'Principal investigator' => 'Principal investigator',
  'principal investigator and author.' => 'Principal investigator',
  'Sponsor' => 'Sponsor',
  'sponsoring body' => 'Sponsor',
  'sponsoring body.' => 'Sponsor',
  'sponsoring and issuing body.' => 'Sponsor',
  'sponsor.' => 'Sponsor',
  'speaker.' => 'Speaker', # Bad data? druid:kp775fq5022
  'issuing body.' => "Issuing body",
  'issuing body,' => "Issuing body",
  'issuing body' => "Issuing body",
  'issuing boyd.' => "Issuing body", # bad data: druid:nn568sd8519
  'photographer,' => 'Photographer', # bad data? druid:hs463hp0639, druid:wz110cw1514
  'researcher' => 'Researcher',
  'researcher.' => 'Researcher',
}

INVALID_ROLES = [
  'Distributor',
  'contributor',
  'Contributor',
  'production company.',
  'compiler',
  'compiler.',
  'designer.',
  'printer.',
  'binder.',
  'participant in a treaty.',
  'enacting jurisdiction.',
  'writer of forward.',
  'addressee',
  'addressee.',
  'commissioning body.',
  'commissioning body,',
  'commissioning body',
  'cre', # see druid:jn023kf3320
  'his', # see druid:jn023kf3320
  'aut', # see druid:ns801cg260 and 19 others
  'ive', # see druid:fg188hk6403 and druid:hd575hm6964
  'ivr', # see druid:fg188hk6403 and druid:hd575hm6964
  'pbl', # see druid:fg188hk6403 and druid:hd575hm6964
  'spk', # on 15 items
  'spn', # on 15 items
  'co-investigator.',
  'Programmer',
  'judge',
  'defendant',
  'plaintiff',
  'writer of added commentary'
]


def load_type_data
  {}.tap do |data|
    CSV.foreach(CSV_FILE, headers: true) do |row|
      druid = "druid:#{row['item_druid']}"
      data[druid] = {
        work_type: row['New Work Type'].downcase,
        subtype: [row['New Subtype 1'], row['New Subtype 2'], row['New Subtype 3'], row['New Subtype 4']].compact
      }
    end
  end
end

def contact_emails(json)
  return [ContactEmail.new(email: json['contact_email'])] if URI::MailTo::EMAIL_REGEXP.match(json['contact_email'])

  warn "Invalid contact email found in #{json['druid']}: #{json['contact_email']}. Setting a dummy value."
  warn json
  [ContactEmail.new(email: 'no-reply@sdr.stanford.edu')]
end

def abstract(json)
  return json['abstract'] if json['abstract']

  warn "Work has no abstract: #{json['druid']}. Setting a dummy value"
  'No abstract entered'
end

def license(json)
  LICENSE.fetch(json.fetch('license'))
end

def split_name(full_name)
  if full_name.include?(',')
    last, first = full_name.split(/,\s*/)
    { last_name: last, first_name: first }
  else
    first, last = full_name.split(' ')
    { last_name: last, first_name: first }
  end
end

def contributors(json)
  json.fetch('contributors').map do |attributes|
    contributor_attributes = attributes.dup
    hydrus_role = contributor_attributes.delete('role')
    case hydrus_role
    when *INVALID_ROLES # H2 doesn't have an equivalent role
      warn "Found role '#{hydrus_role}' for #{json['druid']}, but there is no H2 equivalent role. Skipping."
      next
    when ''
      warn "Found empty role for #{json['druid']}, Skipping."
      next
    end
    role = CONTRIBUTOR_ROLE.fetch(hydrus_role)

    type = CONTRIBUTOR_TYPE.fetch(contributor_attributes.delete('name_type'))
    if type == 'person'
      contributor_attributes.merge!(split_name(contributor_attributes.delete('full_name')))
    end
    Contributor.new(contributor_attributes.merge(contributor_type: type, role: role))
  end.compact
end

def related_links(json)
  json.fetch('related_items').reject { |item| item['url'].blank? }.map { |item| RelatedLink.new(item) }
end

def related_works(json)
  json.fetch('related_citations').reject(&:blank?).map { |citation| RelatedWork.new(citation: citation) }
end

def build_work_attributes(json)
  collection_id = json['collection']
  unless collection_id
    warn "No collection exists for #{json['druid']}. Skipping."
    return
  end

  collection = Collection.find_by(druid: collection_id)
  unless collection
    warn "Unable to find Collection #{collection_id}"
    return
  end

  depositor = User.find_or_create_by!(email: "#{json.dig('creator', 'sunetid')}@stanford.edu")
  {
    depositor: depositor,
    collection: collection,
  }
end

def build_work_version_attributes(json, type_data)
  raw_item_type = json.fetch('item_type')
  work_type = WORK_TYPE.fetch(raw_item_type)

  subtype = case raw_item_type
    when 'thesis', 'article', 'technical report'
      [raw_item_type.capitalize]
    when 'textbook'
      ['Book']
    end

  # Overwrite the values if there was a row in the CSV for this item
  if row = type_data[json['druid']]
    work_type = row.fetch(:work_type)
    subtype = row.fetch(:subtype)
  elsif work_type == 'other'
    warn "#{json['druid']} has a work_type of 'other', but Hydrus doesn't specify a subtype.  Setting a placeholder."
    subtype = ['placeholder']
  elsif work_type == 'mixed material'
    warn "#{json['druid']} has a work_type of 'mixed material', but we don't have subtypes. Skipping"
    return
  end


  title = json['title']
  unless title
    warn "#{json['druid']} does not have a title. #{json}"
    return
  end

  created_edtf = EDTF.parse(json.fetch('date_created')) if json['date_created']
  {
    version: json.fetch('version'),
    abstract: abstract(json),
    contact_emails: contact_emails(json),
    license: license(json),
    title: title,
    work_type: work_type,
    subtype: subtype,
    citation: json['citation'],
    keywords: json.fetch('keywords').map { |text| Keyword.new(label: text) },
    created_edtf: created_edtf,
    state: STATES.fetch(json.fetch('object_status')),
    related_links: related_links(json),
    related_works: related_works(json),
    contributors: contributors(json)
  }
end

def resolve_file(hydrus_path)
  hydrus_path.sub(DEFAULT_DATA_ROOT, DATA_ROOT)
end

def attach_files(json, work_version)
  return unless DATA_ROOT
  json['files'].each do |file_data|
    pathname = resolve_file(file_data['path'])
    filename = File.basename(pathname)
    attached_file = work_version.attached_files.find { |attached| attached.filename == filename }
    next if attached_file

    file = File.open(pathname)
    attached_file = work_version.attached_files.build(label: file_data['label'])
    attached_file.file.attach(io: file, filename: filename)
    attached_file.save!
  end
end

def create_or_update_work(json, type_data)
  work = Work.find_by(druid: json['druid'])
  ActiveRecord::Base.transaction do
    if work
      if work.update(build_work_attributes(json))
        puts "Work #{work.id} - #{work.druid}"
      else
        warn "Validation failed on #{json['druid']}, #{work.errors.full_messages}"
        return
      end
    else
      work = Work.new(build_work_attributes(json).merge(druid: json['druid']))
      if work.save
        puts "Work #{work.id} - #{work.druid}"
      else
        warn "Validation failed on #{json['druid']}, #{work.errors.full_messages}"
        return
      end
    end

    work_version = work.head
    work_version_attrs = build_work_version_attributes(json, type_data)
    return unless work_version_attrs

    if work_version
      work_version.update!(work_version_attrs)
      attach_files(json, work_version)
    else
      work_version = work.build_head(work_version_attrs.
        merge(work_id: work.id, version: json.fetch('version')))
      work_version.save!
      attach_files(json, work_version)
      work.update!(head: work_version)
    end
  end
end

type_data = load_type_data
OFFSET = ARGV[1].present? ? ARGV[1].to_i : 0
count = 0
File.foreach(ARGV[0]) do |data|
  count += 1
  next if count < OFFSET
  json = JSON.parse(data)
  next unless json.present?
  create_or_update_work(json, type_data)
end
